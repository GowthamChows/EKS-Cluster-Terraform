### What is Kubernetes?

Google developed the Kubernetes project in mid-2014 to act as a container orchestrator for the company. Kubernetes (k8s), whose term in Greek means "helmsman", is an *open-source* project that has *design* and development based on the Borg project, which is also from Google [1](https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/). Some other products available on the market, such as Apache Mesos and Cloud Foundry, also emerged from the Borg project. As Kubernetes is a difficult word to pronounce - and to write - the community dubbed it "K8s".

They were conceived and developed in a world where third-party developers were becoming interested in containers and Google has developed a hugely growing business today, which is selling public cloud infrastructure.

Kubernetes is open source - in contrast to Borg and Omega which were developed as purely internal Google systems. Kubernetes was developed with a stronger focus on the experience of developers who write applications that run on a cluster: its main goal is to facilitate the deployment and management of distributed systems while benefiting from the better use of memory and processing resources that containers make possible. 

Information was extracted and adapted from this [article] https://static.googleusercontent.com/media/research.google.com/EN//pubs/archive/44843.pdf), which describes lessons learned from the development and operation of these systems.

### K8s Architecture

The K8s also follows a *control plane/workers* model, thus constituting a *cluster*, where at least three nodes are recommended for its operation: the *control-plane* node, responsible (by default) for managing the *cluster*, and the others as *workers*, executors of the applications we want to run on this *cluster*.

It is possible to create a Kubernetes cluster running on just one node, but it is recommended only for study purposes and never run in a production environment.

If you want to use Kubernetes on your local computer, several solutions are available for creating a Kubernetes cluster, using virtual machines or Docker, for example.

With this, you can have a Kubernetes cluster with several nodes running all of them on your local computer.

Some examples are:

* [Kind](https://kind.sigs.k8s.io/docs/user/quick-start): A tool for running Docker containers that simulate the operation of a Kubernetes cluster. It is used for teaching, development and testing purposes. **Kind should not be used for production**;

* [Minikube](https://github.com/kubernetes/minikube): tool to deploy a Kubernetes *cluster* locally with just one node. Widely used for teaching, development and testing purposes. **Minikube should not be used for production**;

* [MicroK8S](https://microk8s.io): Developed by [Canonical](https://canonical.com), the same company that develops [Ubuntu](https://ubuntu.com). It can be used in different distributions and **can be used in production environments**, especially for *Edge Computing* and IoT (*Internet of things*);

* [k3s](https://k3s.io): Developed by [Rancher Labs](https://rancher.com), it is a direct competitor to MicroK8s, and can even be run on a Raspberry Pi;

* [k0s](https://k0sproject.io): Developed by [Mirantis](https://www.mirantis.com), the same company that acquired the enterprise part of [Docker](https://www.docker .with). It is a Kubernetes distribution with all the resources necessary to operate in a single binary, which provides simplicity in installing and maintaining the cluster. The correct pronunciation is kay-zero-ess and its objective is to reduce the technical effort and wear and tear in installing a Kubernetes cluster, which is why its name alludes to *Zero Friction*. **k0s can be used in production environments**

* **API Server**: It is one of the main components of k8s. This component provides an API that uses JSON over HTTP for communication, where the ``kubectl`` utility is mainly used by administrators to communicate with other nodes, as shown in the graph. These communications between components are established through [REST](https://restfulapi.net) requests;

* **etcd**: etcd is a distributed key-value *datastore* that k8s uses to store *cluster* specifications, status and configurations. All data stored within etcd is manipulated only through the API. For security reasons, etcd is by default only run on nodes classified as *control plane* in the k8s *cluster*, but they can also be run on external *clusters*, specific to etcd, for example;

* **Scheduler**: The *scheduler* is responsible for selecting the node that will host a given *pod* (the smallest unit of a k8s *cluster* - don't worry about that for now, we'll talk more about that later late) to be executed. This selection is made based on the amount of resources available in each node, as well as the state of each of the nodes in the *cluster*, thus ensuring that resources are well distributed. Furthermore, the selection of nodes, on which one or more pods will run, can also take into account user-defined policies, such as affinity, location of data to be read by applications, etc.;

* **Controller Manager**: It is the *controller manager* who guarantees that the *cluster* is in the last state defined in etcd. For example: if in etcd a *deploy* is configured to have ten replicas of a *pod*, it is the *controller manager* who will check if the current state of the *cluster* corresponds to this state and, if not, it will look for reconcile both;

* **Kubelet**: *kubelet* can be seen as the k8s alent that runs on worker nodes. On each worker node, there must be a Kubelet agent running. Kubelet is responsible for actually managing the *pods* that were directed by the *cluster* *controller*, within the nodes, so that Kubelet can start, stop and keep the containers and pods running accordingly as instructed by the cluster controller;

* **Kube-proxy**: Acts as a *proxy* and a *load balancer*. This component is responsible for routing requests to the correct *pods*, as well as taking care of the network part of the node;


